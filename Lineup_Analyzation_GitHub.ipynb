{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import array\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating array of all years to easily iterate through seasons\n",
    "\n",
    "years = [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    year = str(year)\n",
    "    if i != len(years) - 1:\n",
    "        next_year = str(years[i + 1])\n",
    "        years[i] = str(year) + \"-\" + next_year[2:]\n",
    "\n",
    "years = years[0:9]\n",
    "\n",
    "seas_ids = ['22015', '22016', '22017', '22018', '22019', '22020', '22021', '22022', '22023', '22024']\n",
    "\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is necessary for API scraping and was found at the following link: https://github.com/basketballrelativity/synergy/blob/master/synergy_exploration.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "import time\n",
    "\n",
    "from py_ball import league_dash\n",
    "\n",
    "HEADERS = {'Connection': 'keep-alive',\n",
    "           'Host': 'stats.nba.com',\n",
    "           'Origin': 'http://stats.nba.com',\n",
    "           'Upgrade-Insecure-Requests': '1',\n",
    "           'Referer': 'stats.nba.com',\n",
    "           'x-nba-stats-origin': 'stats',\n",
    "           'x-nba-stats-token': 'true',\n",
    "           'Accept-Language': 'en-US,en;q=0.9',\n",
    "           \"X-NewRelic-ID\": \"VQECWF5UChAHUlNTBwgBVw==\",\n",
    "           'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6)' +\\\n",
    "                         ' AppleWebKit/537.36 (KHTML, like Gecko)' + \\\n",
    "                         ' Chrome/81.0.4044.129 Safari/537.36'}\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # Disabling pandas SetWithCopyWarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping lineup data for every season and every team\n",
    "\n",
    "league_id = '00'\n",
    "group_quantity = '5'\n",
    "per_mode = 'Totals'\n",
    "plus_minus = 'N'\n",
    "rank = 'N'\n",
    "pace_adjust = 'N'\n",
    "measure_type = 'Advanced'\n",
    "period = '0'\n",
    "vs_conference = ''\n",
    "last_n_games = '0'\n",
    "location = ''\n",
    "outcome = ''\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    team_df = pd.read_csv(Read in csv for teams)\n",
    "    team_ids = team_df['GROUP_SET'].tolist()\n",
    "    team_net_ratings = team_df['NET_RATING'].tolist()\n",
    "\n",
    "    season = year\n",
    "    vs_division = ''\n",
    "    game_segment = ''\n",
    "    month = '0'\n",
    "    season_type = 'Regular Season'\n",
    "    game_scope = ''\n",
    "    player_experience = ''\n",
    "    player_position = ''\n",
    "    starters_bench = ''\n",
    "\n",
    "    lineup_data = league_dash.LeagueDash(headers=HEADERS,\n",
    "                                endpoint='leaguedashlineups',\n",
    "                                league_id = league_id,\n",
    "                                group_quantity = group_quantity,\n",
    "                                per_mode = per_mode,\n",
    "                                plus_minus = plus_minus,\n",
    "                                rank = rank,\n",
    "                                pace_adjust = pace_adjust,\n",
    "                                measure_type = measure_type,\n",
    "                                period = period,\n",
    "                                vs_conference = vs_conference,\n",
    "                                last_n_games = last_n_games,\n",
    "                                #team_id = team_id,\n",
    "                                location = location,\n",
    "                                outcome = outcome,\n",
    "                                #date_from = date_from,\n",
    "                                #date_to = date_to,\n",
    "                                #opp_team_id = opp_team_id,\n",
    "                                season = season,\n",
    "                                vs_division = vs_division,\n",
    "                                game_segment = game_segment,\n",
    "                                month = month,\n",
    "                                season_type = season_type,\n",
    "                                game_scope = game_scope,\n",
    "                                player_experience = player_experience,\n",
    "                                player_position = player_position,\n",
    "                                starters_bench = starters_bench)\n",
    "    time.sleep(10)\n",
    "\n",
    "    lineup_df = pd.DataFrame(lineup_data.data['Lineups'])\n",
    "    rows_to_drop = []\n",
    "    # print(len(lineup_df))\n",
    "\n",
    "    for i in range(len(lineup_df)):\n",
    "        minutes_together = int(lineup_df.loc[i, 'MIN'])\n",
    "        possessions_together = lineup_df.loc[i, 'POSS']\n",
    "        net_rating = lineup_df.loc[i, 'NET_RATING']\n",
    "        team_identification = lineup_df.loc[i, 'TEAM_ID']\n",
    "        if (possessions_together / 600) >= 1:\n",
    "            lineup_df.loc[i, 'R'] = net_rating\n",
    "        elif (possessions_together / 600) < 1:\n",
    "            index = team_ids.index(team_identification)\n",
    "            team_net_rating = team_net_ratings[index]\n",
    "            lineup_df.loc[i, 'R'] = ((possessions_together / 600) * net_rating) + (1 - (possessions_together / 600)) * team_net_rating\n",
    "        if minutes_together < 48:\n",
    "            rows_to_drop.append(i)\n",
    "\n",
    "    lineup_df = lineup_df.drop(rows_to_drop, axis = 0)\n",
    "    print(f\"{season} lineup information scraped.\")\n",
    "\n",
    "    lineup_df.to_csv(Save csv in each season's folder, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through lineup data frames for each season and counting number of players in each cluster\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    df = pd.read_csv(Read in lineup csv for season)\n",
    "\n",
    "    all_players_df = pd.read_csv(Read in season's csv with player archetypes)\n",
    "\n",
    "    players_ids = all_players_df['PLAYER_ID'].tolist()\n",
    "    players_pie = all_players_df['PIE'].tolist()\n",
    "\n",
    "    for j in range(len(players_ids)):\n",
    "        players_ids[j] = str(players_ids[j])\n",
    "    players_clusters = all_players_df['Cluster'].tolist()\n",
    "\n",
    "    for w in range(len(df)):\n",
    "        group_ids = str(df.loc[w, 'GROUP_ID'])\n",
    "        cleaned_string = group_ids.strip('-')\n",
    "        integer_strings = cleaned_string.split('-')\n",
    "\n",
    "        cluster_0 = 0\n",
    "        cluster_1 = 0\n",
    "        cluster_2 = 0\n",
    "        cluster_3 = 0\n",
    "        cluster_4 = 0\n",
    "        cluster_5 = 0\n",
    "        cluster_6 = 0\n",
    "        cluster_7 = 0\n",
    "        cluster_8 = 0\n",
    "\n",
    "        for j, strings in enumerate(integer_strings):\n",
    "            player_index = players_ids.index(strings)\n",
    "            player_cluster = players_clusters[player_index]\n",
    "            player_pie = players_pie[player_index]\n",
    "            if player_cluster == 0:\n",
    "                cluster_0 += 1\n",
    "            if player_cluster == 1:\n",
    "                cluster_1 += 1\n",
    "            if player_cluster == 2:\n",
    "                cluster_2 += 1\n",
    "            if player_cluster == 3:\n",
    "                cluster_3 += 1\n",
    "            if player_cluster == 4:\n",
    "                cluster_4 += 1\n",
    "            if player_cluster == 5:\n",
    "                cluster_5 += 1\n",
    "            if player_cluster == 6:\n",
    "                cluster_6 += 1\n",
    "            if player_cluster == 7:\n",
    "                cluster_7 += 1\n",
    "            if player_cluster == 8:\n",
    "                cluster_8 += 1\n",
    "        \n",
    "        df.loc[w, \"Cluster_0\"] = cluster_0\n",
    "        df.loc[w, \"Cluster_1\"] = cluster_1\n",
    "        df.loc[w, \"Cluster_2\"] = cluster_2\n",
    "        df.loc[w, \"Cluster_3\"] = cluster_3\n",
    "        df.loc[w, \"Cluster_4\"] = cluster_4\n",
    "        df.loc[w, \"Cluster_5\"] = cluster_5\n",
    "        df.loc[w, \"Cluster_6\"] = cluster_6\n",
    "        df.loc[w, \"Cluster_7\"] = cluster_7\n",
    "        df.loc[w, \"Cluster_8\"] = cluster_8\n",
    "    df.to_csv(Save csv in season's folder, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all lineup information into one data frame\n",
    "\n",
    "lineup_dfs = []\n",
    "\n",
    "for year in years:\n",
    "    df = pd.read_csv(Read in csv's lineup information)\n",
    "    lineup_dfs.append(df)\n",
    "\n",
    "lineup_df = pd.concat(lineup_dfs, axis = 0)\n",
    "lineup_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "lineup_df = lineup_df.sort_values(by='R', ascending=False)\n",
    "\n",
    "lineup_df.to_csv(Save csv, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Random Forest Regressor to predict MSE from correlation between features and target column\n",
    "\n",
    "df = pd.read_csv(Read in csv with all lineups)\n",
    "\n",
    "features = ['MIN', 'POSS', 'Cluster_0', 'Cluster_1', 'Cluster_2', 'Cluster_3', 'Cluster_4', 'Cluster_5', 'Cluster_6', 'Cluster_7', 'Cluster_8']\n",
    "target_column = 'R'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[features]\n",
    "y = df[target_column]\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error (MSE)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Output the MSE value\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Random Forest Regressor to predict net ratings for all lineup combinations\n",
    "df = pd.read_csv(Read in csv with all lineups)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[features]\n",
    "y = df[target_column]\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Set up the grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Asking model for most and least efficient lineups\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Keeping minutes and possessions constant\n",
    "min = 100000000\n",
    "poss = 100000000\n",
    "\n",
    "# Finding all possible five man lineup combinations\n",
    "num_clusters = 9\n",
    "combinations = [comb for comb in itertools.product(range(6), repeat=num_clusters) if sum(comb) == 5]\n",
    "combinations_df = pd.DataFrame(combinations, columns=[f'cluster_{i}' for i in range(num_clusters)])\n",
    "\n",
    "# Add constans to df\n",
    "combinations_df['MIN'] = min\n",
    "combinations_df['POSS'] = poss\n",
    "\n",
    "# Predicting efficiency\n",
    "predictions = best_model.predict(combinations_df)\n",
    "\n",
    "# Add the predictions to the DataFrame\n",
    "combinations_df['Predicted_Net_Rating'] = predictions\n",
    "\n",
    "# Find most and least efficient lineups\n",
    "most_efficient = combinations_df.loc[combinations_df['Predicted_Net_Rating'].idxmax()]\n",
    "least_efficient = combinations_df.loc[combinations_df['Predicted_Net_Rating'].idxmin()]\n",
    "\n",
    "combinations_df = combinations_df.sort_values(by='Predicted_Net_Rating', ascending=False)\n",
    "combinations_df.to_csv(Save csv with lineup combinations and predicted net ratings, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
